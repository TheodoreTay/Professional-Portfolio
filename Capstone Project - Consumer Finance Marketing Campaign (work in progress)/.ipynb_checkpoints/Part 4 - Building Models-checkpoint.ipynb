{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Part 4: Building Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_dataset = pd.read_csv('bank dataset (cleaned).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'age', u'occupation', u'marital', u'education',\n",
       "       u'housing_loan', u'personal_loan', u'contact', u'month', u'day',\n",
       "       u'duration', u'contact_freq', u'days_passed', u'contact_bef',\n",
       "       u'prev_outcome', u'emp_var_rate', u'cpi_index', u'cci_index', u'e3m',\n",
       "       u'employees', u'subscription', u'prev_part'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_dataset = bank_dataset.drop(labels=['Unnamed: 0','days_passed'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous variable dataframe.\n",
    "# We would like to conduct a Pearson's correlation to identify for any potential correlation prior to modelling.\n",
    "# This is a very basic & raw feature selection step.\n",
    "continuous = {}\n",
    "for cols in bank_dataset.columns:\n",
    "        if bank_dataset[cols].dtypes == int:\n",
    "            continuous[cols] = bank_dataset[cols]\n",
    "        elif bank_dataset[cols].dtypes == 'float64':\n",
    "            continuous[cols] = bank_dataset[cols]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = pd.DataFrame(continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop numerical categorical columns, except 'subscription'.\n",
    "continuous = continuous.drop(labels=['prev_part'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous['subscription'] = bank_dataset['subscription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation coefficients.\n",
    "pearsons_table = continuous.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cci_index</th>\n",
       "      <th>contact_bef</th>\n",
       "      <th>contact_freq</th>\n",
       "      <th>cpi_index</th>\n",
       "      <th>duration</th>\n",
       "      <th>e3m</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>employees</th>\n",
       "      <th>subscription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cci_index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact_bef</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact_freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpi_index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667198</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e3m</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969408</td>\n",
       "      <td>0.944864</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_var_rate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employees</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944864</td>\n",
       "      <td>0.900361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscription</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  cci_index  contact_bef  contact_freq  cpi_index  duration  \\\n",
       "age           1.0        NaN          NaN           NaN        NaN       NaN   \n",
       "cci_index     NaN        1.0          NaN           NaN        NaN       NaN   \n",
       "contact_bef   NaN        NaN          1.0           NaN        NaN       NaN   \n",
       "contact_freq  NaN        NaN          NaN           1.0        NaN       NaN   \n",
       "cpi_index     NaN        NaN          NaN           NaN   1.000000       NaN   \n",
       "duration      NaN        NaN          NaN           NaN        NaN       1.0   \n",
       "e3m           NaN        NaN          NaN           NaN   0.667198       NaN   \n",
       "emp_var_rate  NaN        NaN          NaN           NaN   0.765986       NaN   \n",
       "employees     NaN        NaN          NaN           NaN        NaN       NaN   \n",
       "subscription  NaN        NaN          NaN           NaN        NaN       NaN   \n",
       "\n",
       "                   e3m  emp_var_rate  employees  subscription  \n",
       "age                NaN           NaN        NaN           NaN  \n",
       "cci_index          NaN           NaN        NaN           NaN  \n",
       "contact_bef        NaN           NaN        NaN           NaN  \n",
       "contact_freq       NaN           NaN        NaN           NaN  \n",
       "cpi_index     0.667198      0.765986        NaN           NaN  \n",
       "duration           NaN           NaN        NaN           NaN  \n",
       "e3m           1.000000      0.969408   0.944864           NaN  \n",
       "emp_var_rate  0.969408      1.000000   0.900361           NaN  \n",
       "employees     0.944864      0.900361   1.000000           NaN  \n",
       "subscription       NaN           NaN        NaN           1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsons_table[(pearsons_table>0.5) | (pearsons_table<-0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "- As we can see, there is a strong positive correlation between (e3m & emp_var_rate/employees) AND (emp_var_rate & employees).\n",
    "- This is largely due to these factors having a strong influence on one another by definition.\n",
    "- We will not drop them just yet (until we have conducted further feature selection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to learn:\n",
    "- SVM\n",
    "- CART\n",
    "- ensemble\n",
    "- pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preliminary modelling (without up or down sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bank_dataset['subscription']\n",
    "X = bank_dataset.drop(labels='subscription',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26616\n",
       "1     3858\n",
       "Name: subscription, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734002756448119"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what you will be comparing your model accuracy against.\n",
    "1.0 - np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy encode, Standard Scale & Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy encode categories with more than 2 outcomes.\n",
    "X_dummed = pd.get_dummies(X, columns= ['occupation','marital','education','housing_loan','personal_loan','contact','month','day','prev_outcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler.\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X_dummed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.35, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_scores\n",
      "[0.89909183 0.89808274 0.89707366 0.90257446 0.89298334 0.90808081\n",
      " 0.8979798  0.90353535 0.91161616 0.8969697 ]\n",
      "--------\n",
      "0.9007987851380148\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = cross_val_score(log_reg, X_train, y_train, cv=10)\n",
    "print 'accuracy_scores'\n",
    "print accuracy_scores\n",
    "print '--------'\n",
    "print np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deriving accuracy score on test set.\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.899962497656\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "print ('accuracy = {}'.format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "<br>The 'Accuracy Score' of 0.899 for logistic regression model is slightly better than baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conf matrix, ROC-AUC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition:\n",
    "- Simple algorithm based on distances from a stipulated number of 'K' neighbours (e.g. 3, 5, 10 etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88597376 0.88294652 0.87891019 0.88036345 0.8859162  0.88585859\n",
      " 0.87424242 0.87474747 0.88232323 0.88737374]\n",
      "0.8818655585552891\n"
     ]
    }
   ],
   "source": [
    "# Comparing accuracy score to baseline.\n",
    "accuracy_score = cross_val_score(knn, X_train, y_train, cv=10)\n",
    "print(accuracy_score)\n",
    "print np.mean(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deriving accuracy score on test set.\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.883367710482\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print ('accuracy = {}'.format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "<br>The 'Accuracy Score' of 0.88 for knn model is slightly better than baseline accuracy.\n",
    "<br> Chances are we will not use knn for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Up/Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN combination of over- & under- sampling.\n",
    "smote_enn = SMOTEENN(random_state=8)\n",
    "X_trainresam, y_trainresam = smote_enn.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 13981), (1, 16638)]\n"
     ]
    }
   ],
   "source": [
    "# Counting the y output variables.\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_trainresam).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Selection & Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection (SelectKBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(X_dummed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>f_classif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>employees</td>\n",
       "      <td>14519.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e3m</td>\n",
       "      <td>13355.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emp_var_rate</td>\n",
       "      <td>12233.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duration</td>\n",
       "      <td>10326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prev_part</td>\n",
       "      <td>3873.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feature f_classif\n",
       "8     employees   14519.8\n",
       "7           e3m   13355.6\n",
       "4  emp_var_rate   12233.7\n",
       "1      duration     10326\n",
       "9     prev_part   3873.94"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "skb_f = SelectKBest(f_classif, k=5)\n",
    "skb_f.fit(X_trainresam, y_trainresam)\n",
    "\n",
    "\n",
    "kbest = pd.DataFrame([cols, list(skb_f.scores_)], \n",
    "                     index=['feature','f_classif']).T.sort_values('f_classif', ascending=False)\n",
    "\n",
    "kbest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True  True  True  True  True  True  True False\n",
      "  True False  True  True False  True False False  True  True  True False\n",
      " False  True  True  True False  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False False False False]\n",
      "[10  1  1  1  1  1  1  1  1  1  1  7  1 11  1  1  2  1  6  4  1  1  1  9\n",
      " 14  1  1  1 13  1  1  1  1  1  1  1  1  1  1  1  1  1  3  8 12  5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "selector = RFECV(log_reg, step=1, cv=10)\n",
    "selector = selector.fit(X_trainresam, y_trainresam)\n",
    "\n",
    "print selector.support_\n",
    "print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['duration', 'contact_freq', 'contact_bef', 'emp_var_rate',\n",
       "       'cpi_index', 'cci_index', 'e3m', 'employees', 'prev_part',\n",
       "       'occupation_blue-collar', 'occupation_housemaid',\n",
       "       'occupation_retired', 'occupation_self-employed',\n",
       "       'occupation_student', 'marital_married', 'marital_single',\n",
       "       'education_basic.6y', 'education_illiterate',\n",
       "       'education_professional.course', 'education_university.degree',\n",
       "       'personal_loan_yes', 'contact_telephone', 'month_aug', 'month_dec',\n",
       "       'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov',\n",
       "       'month_oct', 'month_sep', 'day_mon', 'day_thu'], dtype='|S29')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv_columns = np.array(cols)[selector.support_]\n",
    "rfecv_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_excluded = []\n",
    "for columns in cols:\n",
    "    if columns not in rfecv_columns:\n",
    "        RFE_excluded.append(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'occupation_entrepreneur',\n",
       " 'occupation_management',\n",
       " 'occupation_services',\n",
       " 'occupation_technician',\n",
       " 'occupation_unemployed',\n",
       " 'education_basic.9y',\n",
       " 'education_high.school',\n",
       " 'housing_loan_yes',\n",
       " 'day_tue',\n",
       " 'day_wed',\n",
       " 'prev_outcome_nonexistent',\n",
       " 'prev_outcome_success']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Excluded features.\n",
    "RFE_excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection (Lasso Penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "log_rcv = LogisticRegressionCV(penalty='l1', Cs=100, cv=10, solver='liblinear')\n",
    "log_rcv.fit(X_trainresam, y_trainresam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame(log_rcv.coef_, columns=X_dummed.columns)\n",
    "coeffs_t = coeffs.transpose()\n",
    "coeffs_t.columns = ['lasso_coefs']\n",
    "coeffs_abs = coeffs_t.abs().sort_values('lasso_coefs', ascending=False)\n",
    "coeffs_abs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "<br> The F-test is explained variance divided by unexplained variance. High numbers will result if our explained variance (what we know) is much greater than our unexplained variance (what we don't know)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Remodelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
