{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Part 4: Building Models (cont'd)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_dataset = pd.read_csv('bank dataset (cleaned).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_dataset = bank_dataset.drop(labels=['Unnamed: 0','days_passed'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our Predictor & Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bank_dataset['subscription']\n",
    "X = bank_dataset.drop(labels=['subscription','age','employees','e3m'],axis=1)\n",
    "# X columns dropped based on feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy encode categories with more than 2 outcomes.\n",
    "X_dummed = pd.get_dummies(X, columns= ['occupation','marital','education','housing_loan','personal_loan','contact','month','day','prev_outcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler.\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X_dummed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.35, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN combination of over- & under- sampling.\n",
    "smote_enn = SMOTEENN(random_state=8)\n",
    "X_trainresam, y_trainresam = smote_enn.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 14002), (1, 16306)]\n"
     ]
    }
   ],
   "source": [
    "# Counting the y output variables.\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_trainresam).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Baseline Accuracy (following balancing of dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5380097663983107"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_trainresam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 8: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(X_trainresam, y_trainresam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_scores\n",
      "[0.9224934  0.95316623 0.96898713 0.96634774 0.9643682  0.96601782\n",
      " 0.9679868  0.96831683 0.97062706 0.96468647]\n",
      "--------\n",
      "0.9612997676519666\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated best accuracy score.\n",
    "accuracy_scores = cross_val_score(GBC, X_trainresam, y_trainresam, cv=10, scoring='accuracy')\n",
    "\n",
    "print 'accuracy_scores'\n",
    "print accuracy_scores\n",
    "print '--------'\n",
    "print np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.865366585412\n"
     ]
    }
   ],
   "source": [
    "# Deriving accuracy score on test set.\n",
    "y_pred = GBC.predict(X_test)\n",
    "print ('accuracy = {}'.format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8653665854115882"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deriving accuracy score alternative?\n",
    "GBC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.86      0.92      9271\n",
      "          1       0.49      0.88      0.63      1395\n",
      "\n",
      "avg / total       0.92      0.87      0.88     10666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Derive classification report.\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8710951674566972"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute ROC_AUC score.\n",
    "metrics.roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__\n",
    "<br> As this model is selected to be the best out of all, we will be constructing a confusion matrix, analysing to see what is the value of the false negatives, and make an attempt to reduce it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_did_not</th>\n",
       "      <th>predicted_subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>did_not</th>\n",
       "      <td>8004</td>\n",
       "      <td>1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscribed</th>\n",
       "      <td>169</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted_did_not  predicted_subscribed\n",
       "did_not                  8004                  1267\n",
       "subscribed                169                  1226"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conmat = np.array(confusion_matrix(y_test, y_pred, labels=[0,1]))\n",
    "\n",
    "confusion_table = pd.DataFrame(conmat, index=['did_not', 'subscribed'],\n",
    "                         columns=['predicted_did_not','predicted_subscribed'])\n",
    "confusion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowering the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0_pp</th>\n",
       "      <th>class_1_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.992995</td>\n",
       "      <td>0.007005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981713</td>\n",
       "      <td>0.018287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792149</td>\n",
       "      <td>0.207851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995374</td>\n",
       "      <td>0.004626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.993962</td>\n",
       "      <td>0.006038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_0_pp  class_1_pp\n",
       "0    0.992995    0.007005\n",
       "1    0.981713    0.018287\n",
       "2    0.792149    0.207851\n",
       "3    0.995374    0.004626\n",
       "4    0.993962    0.006038"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pp = pd.DataFrame(GBC.predict_proba(X_test), columns=['class_0_pp','class_1_pp'])\n",
    "y_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion table for cut-off values 0.1\n",
      "            predicted_did_not  predicted_subscribed\n",
      "did_not                  6855                  2416\n",
      "subscribed                 37                  1358\n",
      "--------------\n",
      "confusion table for cut-off values 0.2\n",
      "            predicted_did_not  predicted_subscribed\n",
      "did_not                  7334                  1937\n",
      "subscribed                 74                  1321\n",
      "--------------\n",
      "confusion table for cut-off values 0.3\n",
      "            predicted_did_not  predicted_subscribed\n",
      "did_not                  7613                  1658\n",
      "subscribed                109                  1286\n",
      "--------------\n",
      "confusion table for cut-off values 0.4\n",
      "            predicted_did_not  predicted_subscribed\n",
      "did_not                  7827                  1444\n",
      "subscribed                134                  1261\n",
      "--------------\n",
      "confusion table for cut-off values 0.5\n",
      "            predicted_did_not  predicted_subscribed\n",
      "did_not                  8004                  1267\n",
      "subscribed                169                  1226\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "cutoffs = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "col_names = ['0.1','0.2','0.3','0.4', '0.5']\n",
    "\n",
    "for index, threshold in enumerate(cutoffs):\n",
    "    y_pp[col_names[index]] = [1.0 if values >= threshold else 0.0 for values in y_pp['class_1_pp']]\n",
    "    \n",
    "    conmat = np.array(confusion_matrix(y_test, y_pp[col_names[index]], labels=[0,1]))\n",
    "    \n",
    "    confusion_table = pd.DataFrame(conmat, index=['did_not', 'subscribed'],\n",
    "                         columns=['predicted_did_not','predicted_subscribed'])\n",
    "    \n",
    "    print 'confusion table for cut-off values {}'.format(col_names[index])\n",
    "    print confusion_table\n",
    "    print '--------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_0_pp</th>\n",
       "      <th>class_1_pp</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.992995</td>\n",
       "      <td>0.007005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981713</td>\n",
       "      <td>0.018287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792149</td>\n",
       "      <td>0.207851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.995374</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.993962</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_0_pp  class_1_pp  0.1  0.2  0.3  0.4\n",
       "0    0.992995    0.007005  0.0  0.0  0.0  0.0\n",
       "1    0.981713    0.018287  0.0  0.0  0.0  0.0\n",
       "2    0.792149    0.207851  1.0  1.0  0.0  0.0\n",
       "3    0.995374    0.004626  0.0  0.0  0.0  0.0\n",
       "4    0.993962    0.006038  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 9: Gradient Boosting + Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, Iâ€™ll test max_depth values of 5 to 15 in steps of 2 and min_samples_split from 200 to 1000 in steps of 200. These are just based on my intuition. You can set wider ranges as well and then perform multiple iterations for smaller ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth':[None,3,6,9], 'min_samples_split':range(100,901,200)}\n",
    "\n",
    "GBC_gs = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=15, max_features='sqrt', subsample=0.8, random_state=8), \n",
    "param_grid = param, scoring='accuracy',n_jobs=4,iid=False, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=15,\n",
       "              presort='auto', random_state=8, subsample=0.8, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'min_samples_split': [100, 300, 500, 700, 900], 'max_depth': [None, 3, 6, 9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC_gs.fit(X_trainresam, y_trainresam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters\n",
      "{'min_samples_split': 100, 'max_depth': None}\n",
      "best score achieved\n",
      "0.9652574820733468\n"
     ]
    }
   ],
   "source": [
    "# Cross-validated best accuracy score.\n",
    "print 'best parameters'\n",
    "print GBC_gs.best_params_\n",
    "print 'best score achieved'\n",
    "print GBC_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_GBC = GBC_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.860866304144\n"
     ]
    }
   ],
   "source": [
    "# Deriving accuracy score on test set.\n",
    "y_pred = best_GBC.predict(X_test)\n",
    "print ('accuracy = {}'.format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.860866304144009"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deriving accuracy score alternative?\n",
    "best_GBC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.86      0.91      9271\n",
      "          1       0.48      0.88      0.62      1395\n",
      "\n",
      "avg / total       0.91      0.86      0.88     10666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Derive classification report.\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8703333978966283"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute ROC_AUC score.\n",
    "metrics.roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
