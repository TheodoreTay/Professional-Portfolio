{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Part 4: Classification Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_dataset = pd.read_csv('bank dataset (cleaned).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'age', u'occupation', u'marital', u'education',\n",
       "       u'housing_loan', u'personal_loan', u'contact', u'month', u'day',\n",
       "       u'duration', u'contact_freq', u'days_passed', u'contact_bef',\n",
       "       u'prev_outcome', u'emp_var_rate', u'cpi_index', u'cci_index', u'e3m',\n",
       "       u'employees', u'subscription', u'prev_part'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_dataset = bank_dataset.drop(labels=['Unnamed: 0','days_passed'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous variable dataframe.\n",
    "# We would like to conduct a Pearson's correlation to identify for any potential correlation prior to modelling.\n",
    "# This is a very basic & raw feature selection step.\n",
    "continuous = {}\n",
    "for cols in bank_dataset.columns:\n",
    "        if bank_dataset[cols].dtypes == int:\n",
    "            continuous[cols] = bank_dataset[cols]\n",
    "        elif bank_dataset[cols].dtypes == 'float64':\n",
    "            continuous[cols] = bank_dataset[cols]\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = pd.DataFrame(continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop numerical categorical columns, except 'subscription'.\n",
    "continuous = continuous.drop(labels=['prev_part'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous['subscription'] = bank_dataset['subscription']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation coefficients.\n",
    "pearsons_table = continuous.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>cci_index</th>\n",
       "      <th>contact_bef</th>\n",
       "      <th>contact_freq</th>\n",
       "      <th>cpi_index</th>\n",
       "      <th>duration</th>\n",
       "      <th>e3m</th>\n",
       "      <th>emp_var_rate</th>\n",
       "      <th>employees</th>\n",
       "      <th>subscription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cci_index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact_bef</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact_freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpi_index</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667198</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e3m</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969408</td>\n",
       "      <td>0.944864</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_var_rate</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.969408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900361</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employees</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944864</td>\n",
       "      <td>0.900361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subscription</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  cci_index  contact_bef  contact_freq  cpi_index  duration  \\\n",
       "age           1.0        NaN          NaN           NaN        NaN       NaN   \n",
       "cci_index     NaN        1.0          NaN           NaN        NaN       NaN   \n",
       "contact_bef   NaN        NaN          1.0           NaN        NaN       NaN   \n",
       "contact_freq  NaN        NaN          NaN           1.0        NaN       NaN   \n",
       "cpi_index     NaN        NaN          NaN           NaN   1.000000       NaN   \n",
       "duration      NaN        NaN          NaN           NaN        NaN       1.0   \n",
       "e3m           NaN        NaN          NaN           NaN   0.667198       NaN   \n",
       "emp_var_rate  NaN        NaN          NaN           NaN   0.765986       NaN   \n",
       "employees     NaN        NaN          NaN           NaN        NaN       NaN   \n",
       "subscription  NaN        NaN          NaN           NaN        NaN       NaN   \n",
       "\n",
       "                   e3m  emp_var_rate  employees  subscription  \n",
       "age                NaN           NaN        NaN           NaN  \n",
       "cci_index          NaN           NaN        NaN           NaN  \n",
       "contact_bef        NaN           NaN        NaN           NaN  \n",
       "contact_freq       NaN           NaN        NaN           NaN  \n",
       "cpi_index     0.667198      0.765986        NaN           NaN  \n",
       "duration           NaN           NaN        NaN           NaN  \n",
       "e3m           1.000000      0.969408   0.944864           NaN  \n",
       "emp_var_rate  0.969408      1.000000   0.900361           NaN  \n",
       "employees     0.944864      0.900361   1.000000           NaN  \n",
       "subscription       NaN           NaN        NaN           1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsons_table[(pearsons_table>0.5) | (pearsons_table<-0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "- As we can see, there is a strong positive correlation between (e3m & emp_var_rate/employees) AND (emp_var_rate & employees).\n",
    "- This is largely due to these factors having a strong influence on one another by definition.\n",
    "- We will not drop them just yet (until we have conducted further feature selection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to learn:\n",
    "- SVM\n",
    "- CART\n",
    "- ensemble\n",
    "- pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preliminary modelling (without up or down sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bank_dataset['subscription']\n",
    "X = bank_dataset.drop(labels='subscription',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26616\n",
       "1     3858\n",
       "Name: subscription, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734002756448119"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what you will be comparing your model accuracy against.\n",
    "1.0 - np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy encode, Standard Scale & Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy encode categories with more than 2 outcomes.\n",
    "X_dummed = pd.get_dummies(X, columns= ['occupation','marital','education','housing_loan','personal_loan','contact','month','day','prev_outcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler.\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X_dummed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.35, random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_scores\n",
      "[0.89909183 0.89808274 0.89707366 0.90257446 0.89298334 0.90808081\n",
      " 0.8979798  0.90353535 0.91161616 0.8969697 ]\n",
      "--------\n",
      "0.9007987851380148\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = cross_val_score(log_reg, X_train, y_train, cv=10)\n",
    "print 'accuracy_scores'\n",
    "print accuracy_scores\n",
    "print '--------'\n",
    "print np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conf matrix, ROC-AUC?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "<br>The mean 'Accuracy Score' of 0.90 for a simple logistic regression model is pretty good given that it is higher than the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition:\n",
    "- Simple algorithm based on distances from a stipulated number of 'K' neighbours (e.g. 3, 5, 10 etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune for best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88597376 0.88294652 0.87891019 0.88036345 0.8859162  0.88585859\n",
      " 0.87424242 0.87474747 0.88232323 0.88737374]\n",
      "0.8818655585552891\n"
     ]
    }
   ],
   "source": [
    "# Comparing accuracy score to baseline.\n",
    "accuracy_score = cross_val_score(knn, X_train, y_train, cv=10)\n",
    "print(accuracy_score)\n",
    "print np.mean(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deriving accuracy score on test set.\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.883367710482\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print ('accuracy = {}'.format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__\n",
    "<br>The mean 'Accuracy Score' of 0.88 for knn model is slightly better than baseline accuracy.\n",
    "<br> Chances are we will not use knn for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Up/Down Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN combination of over- & under- sampling.\n",
    "smote_enn = SMOTEENN(random_state=8)\n",
    "X_trainresam, y_trainresam = smote_enn.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 13981), (1, 16638)]\n"
     ]
    }
   ],
   "source": [
    "# Counting the y output variables.\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_trainresam).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Selection & Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection.\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "\n",
    "cols = list(X_train.columns)\n",
    "\n",
    "skb_f = SelectKBest(f_classif, k=5)\n",
    "skb_chi2 = SelectKBest(chi2, k=5)\n",
    "\n",
    "skb_f.fit(X_train, y_train)\n",
    "skb_chi2.fit(X_train, y_train)\n",
    "\n",
    "kbest = pd.DataFrame([cols, list(skb_f.scores_), list(skb_chi2.scores_)], \n",
    "                     index=['feature','f_classif','chi2 score']).T.sort_values('f_classif', ascending=False)\n",
    "kbest\n",
    "\n",
    "# Note: The F-test refers to explained variance divided by unexplained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection.\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "selector = RFECV(lr, step=1, cv=10)\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "print selector.support_\n",
    "print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv_columns = np.array(cols)[selector.support_]\n",
    "rfecv_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection through regularisation.\n",
    "Lasso Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Remodelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
